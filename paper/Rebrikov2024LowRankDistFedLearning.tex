\documentclass{article}
\usepackage{arxiv}

\usepackage[utf8]{inputenc}
\usepackage[T1,T2A]{fontenc}
\usepackage[english, russian]{babel}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}



\title{Методы малоранговых разложений в распределенном и федеративном обучении}

\author{ Ребриков Алексей \\
	\texttt{rebrikov.av@phystech.edu} \\
	%% examples of more authors
	\And
	Зыль Александр\\
	% \texttt{beznosikov.an@phystech.edu} \\
	\And 
	Безносиков Александр\\
	\texttt{beznosikov.an@phystech.edu} \\
	%% \AND
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}
\date{}
\renewcommand{\undertitle}{}

\hypersetup{
pdftitle={Методы малоранговых разложений в распределенном и федеративном обучении},
pdfsubject={Малоранговые разложения},
pdfauthor={Ребриков~А.В., Безносиков~А.Н., Зыль~А.В.},
pdfkeywords={сжатие информации, малоранговые разложения, распределенное обучение, федеративное обучение},
}

\begin{document}
\maketitle

\begin{abstract}
	Подходы распределенного и федеративного обучения становятся все более популярными в обучении современных SOTA моделей машинного обучения. При этом на первый план выходит вопрос организации эффективных коммуникаций, так как процесс передачи информации занимает слишком много времени даже в случае кластерных вычислений. Из-за этого может теряться смысл в распределении/распараллеливании процесса обучения. Одной из ключевой техник  борьбы с коммуникационными затратами является использование сжатий передаваемой информации. На данный момент в литературе предлагаются различные техники сжатия (\citep{beznosikov2023biased}, \citep{alistarh2017qsgd}, \citep{horvoth2022natural}), но потенциал в этом вопросе явно не исчерпан. В частности, довольно большой потенциал кроется в малоранговых разложениях \citep{Gundersen2019RSVD}. В рамках проекта предлагается сконструировать операторы сжатия на основе данных разложений и встроить в методы распределенной оптимизации \citep{richtarik2021ef21}.
\end{abstract}


\keywords{сжатие информации \and малоранговые разложения \and распределенное обучение \and федеративное обучение}

\section{Введение}

Цель данного исследования заключается в разработке и анализе методов малоранговых разложений для сжатия информации в контексте распределенного и федеративного обучения. Мотивация исследования проистекает из растущей потребности в эффективных методах обучения для современных масштабных моделей машинного обучения, где коммуникационные затраты становятся критическим барьером для эффективности.

Объектом исследования являются операторы сжатия, основанные на малоранговых разложениях, и их интеграция в методы распределенной оптимизации. Проблемой, которую мы решаем, является высокая коммуникационная нагрузка при обучении моделей в распределенных системах, ограничивающая масштабируемость и эффективность процессов.

В рамках методологии проводится обзор существующей литературы и анализируются последние достижения в области сжатия информации для распределенного обучения. В частности, рассматриваются существующие техники сжатия, такие как предложенные в работах \citep{beznosikov2023biased}, \citep{alistarh2017qsgd}, и \citep{horvoth2022natural}, а также исследуется потенциал малоранговых разложений.

Задачами проекта являются разработка операторов сжатия на основе малоранговых разложений, их интеграция в алгоритмы распределенной оптимизации и оценка влияния на эффективность обучения. Предлагаемое решение предполагает новизну в виде конкретной реализации сжатия, которая потенциально позволяет уменьшить коммуникационные затраты без значительной потери качества обучения.

Цель эксперимента состоит в демонстрации эффективности предлагаемых методов на реальных наборах данных и в различных условиях обучения, оценке улучшения скорости и качества обучения.

\bibliographystyle{unsrtnat}
\bibliography{references}

\end{document}